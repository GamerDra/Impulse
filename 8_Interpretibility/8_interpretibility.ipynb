{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10495954,"sourceType":"datasetVersion","datasetId":6498595}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Task 8: Interpretability of the Best Model\n\nThis document provides a detailed explanation of the code for training, evaluating, and interpreting a 1D Convolutional Neural Network (CNN) model, which was decided to be our Best model for EEG seizure detection.\n\n## Requirements\n- numpy\n- torch\n- sklearn\n- seaborn\n- matplotlib\n- pandas\n- limeimport\n- collections\n\n## Code Overview\n\n### Part 1. Classifying Data using 1DCNN model\nSimilar to what we have done in task 7. We train a 1D CNN model to classify the given test data to one of 4 classes of seizure data. The steps in this part are as following:\n\n- Importing libraries\n- Defining Utility functions\n- Loading the data\n- Training the model\n- Evaluating the model's performance on validation_data\n- Making test predictions and saving them\n\n### Part 2. Using LIME to evaluate the impact of channels\nLIME (Local Interpretable Model-agnostic Explanations) explains predictions of machine learning models by approximating them locally with simpler interpretable models, like linear regressions. It perturbs input data, observes prediction changes, and identifies important features influencing the model's decision. This helps understand complex model behavior for individual predictions without altering the original model.\n\nBy this method we find out the following valuable information:\n\nClass 0 : Most important channels are Channel 0, 3 and 17\n\nClass 1 : Most important channels are Channel 8, 14 and 2\n\nClass 2 : Most important channels are Channel 11, 4, and 7\n\nClass 3 : Most important channels are Channel 12, 6 and 10\n\n### Part 3. Running the model without the most impactful channels\n\nMasking a particular channel would impact its precision and recall for that particular class.\n","metadata":{}},{"cell_type":"markdown","source":"# PART 1","metadata":{}},{"cell_type":"markdown","source":"## 1. Importing Libraries\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.utils.class_weight import compute_class_weight\nimport pandas as pd\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:24:11.806895Z","iopub.execute_input":"2025-01-19T11:24:11.807401Z","iopub.status.idle":"2025-01-19T11:24:11.813442Z","shell.execute_reply.started":"2025-01-19T11:24:11.807351Z","shell.execute_reply":"2025-01-19T11:24:11.811980Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## 2. Defining Utility Functions","metadata":{}},{"cell_type":"code","source":"def set_seed(seed=42):\n    \"\"\"Set random seed for reproducibility.\"\"\"\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nset_seed()\n\n# Paths\nbase_path = \"/kaggle/input/impulse/Impulse/EEG_Data\"\ntrain_path = os.path.join(base_path, \"train_data\")\nval_path = os.path.join(base_path, \"validation_data\")\ntest_path = os.path.join(base_path, \"test_data\")\n\nclass_mapping = {\n    \"Complex_Partial_Seizures\": 1,\n    \"Electrographic_Seizures\": 2,\n    \"Video_detected_Seizures_with_no_visual_change_over_EEG\": 3,\n    \"Normal\": 0\n}\n\ndef load_labeled_data(data_path, class_mapping):\n    data, labels = [], []\n    for class_name, label in class_mapping.items():\n        class_folder = os.path.join(data_path, class_name)\n        if os.path.exists(class_folder):\n            for file in os.listdir(class_folder):\n                if file.endswith(\".npy\"):\n                    sample = np.load(os.path.join(class_folder, file))\n                    data.append(sample)\n                    labels.append(label)\n    return np.array(data), np.array(labels)\n\ndef load_unlabeled_data(data_path):\n    data, filenames = [], []\n    for file in os.listdir(data_path):\n        if file.endswith(\".npy\"):\n            sample = np.load(os.path.join(data_path, file))\n            data.append(sample)\n            filenames.append(file)\n    return np.array(data), filenames","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:24:11.815027Z","iopub.execute_input":"2025-01-19T11:24:11.815399Z","iopub.status.idle":"2025-01-19T11:24:11.841679Z","shell.execute_reply.started":"2025-01-19T11:24:11.815370Z","shell.execute_reply":"2025-01-19T11:24:11.840432Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## 3. Data Loading","metadata":{}},{"cell_type":"code","source":"# Data Loading\ntrain_data, train_labels = load_labeled_data(train_path, class_mapping)\nval_data, val_labels = load_labeled_data(val_path, class_mapping)\ntest_data, test_filenames = load_unlabeled_data(test_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:24:11.843271Z","iopub.execute_input":"2025-01-19T11:24:11.843672Z","iopub.status.idle":"2025-01-19T11:24:11.878946Z","shell.execute_reply.started":"2025-01-19T11:24:11.843632Z","shell.execute_reply":"2025-01-19T11:24:11.877177Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-a630fd619131>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_labeled_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_labeled_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_unlabeled_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-f9940927cc6d>\u001b[0m in \u001b[0;36mload_unlabeled_data\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_unlabeled_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/impulse/Impulse/EEG_Data/test_data'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/impulse/Impulse/EEG_Data/test_data'","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"def normalize_data(data):\n    mean = data.mean(axis=(0, 2), keepdims=True)\n    std = data.std(axis=(0, 2), keepdims=True) + 1e-8\n    return ((data - mean) / std).astype(np.float32)\n\ntrain_data = normalize_data(train_data)\nval_data = normalize_data(val_data)\ntest_data = normalize_data(test_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:24:11.879564Z","iopub.status.idle":"2025-01-19T11:24:11.879895Z","shell.execute_reply":"2025-01-19T11:24:11.879770Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class EEGDataset1D(Dataset):\n    def __init__(self, data, labels=None, augment=False):\n        self.data = torch.tensor(data, dtype=torch.float32)\n        print(f\"Permuted data shape: {self.data.shape}\")  # Debug: Confirm shape\n        self.labels = torch.tensor(labels, dtype=torch.long) if labels is not None else None\n        self.augment = augment # Augmentation flag\n\n    def __len__(self):\n        return len(self.data)  # Number of samples\n\n    def __getitem__(self, idx):\n        # Retrieve sample and (optionally) add noise\n        sample = self.data[idx]\n        if self.augment:\n            sample = self.add_noise(sample.numpy())\n        if self.labels is not None:\n            return sample, self.labels[idx]  # Return sample with label\n        return sample  # Return only sample for test data\n\n    def add_noise(self, sample, noise_level=0.05):\n        # Add Gaussian noise for augmentation\n        noise = np.random.randn(*sample.shape) * noise_level\n        return torch.tensor(sample + noise, dtype=torch.float32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:24:11.880558Z","iopub.status.idle":"2025-01-19T11:24:11.880854Z","shell.execute_reply":"2025-01-19T11:24:11.880740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = EEGDataset1D(train_data, train_labels, augment=True)\nval_dataset = EEGDataset1D(val_data, val_labels)\ntest_dataset = EEGDataset1D(test_data)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:24:11.881843Z","iopub.status.idle":"2025-01-19T11:24:11.882157Z","shell.execute_reply":"2025-01-19T11:24:11.882016Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Training the model","metadata":{}},{"cell_type":"code","source":"def initialize_weights(module):\n    if isinstance(module, nn.Conv1d) or isinstance(module, nn.Linear):\n        nn.init.xavier_uniform_(module.weight)\n        if module.bias is not None:\n            nn.init.zeros_(module.bias)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:24:11.883009Z","iopub.status.idle":"2025-01-19T11:24:11.883408Z","shell.execute_reply":"2025-01-19T11:24:11.883243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Simple1DCNN(nn.Module):\n    def __init__(self, input_channels, input_length, num_classes):\n        super(Simple1DCNN, self).__init__()\n        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool1d(2)\n        self.batch_norm = nn.BatchNorm1d(64)\n        self.relu = nn.ReLU()\n\n        dummy_input = torch.zeros(1, input_channels, input_length)\n        self.flattened_size = self._get_flattened_size(dummy_input)\n\n        self.fc1 = nn.Linear(self.flattened_size, 128)\n        self.fc2 = nn.Linear(128, 64)\n        self.fc3 = nn.Linear(64, num_classes)\n        self.dropout = nn.Dropout(0.5)\n\n        self.apply(initialize_weights)\n\n    def _get_flattened_size(self, x):\n        x = self.pool(self.relu(self.conv1(x)))\n        x = self.pool(self.relu(self.conv2(x)))\n        return x.view(x.size(0), -1).size(1)\n\n    def forward(self, x):\n        x = self.pool(self.relu(self.conv1(x)))\n        x = self.pool(self.relu(self.conv2(x)))\n        x = self.batch_norm(x)\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.relu(self.fc2(x))\n        x = self.dropout(x)\n        x = self.fc3(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:24:11.944294Z","iopub.execute_input":"2025-01-19T11:24:11.944652Z","iopub.status.idle":"2025-01-19T11:24:11.953703Z","shell.execute_reply.started":"2025-01-19T11:24:11.944620Z","shell.execute_reply":"2025-01-19T11:24:11.952491Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"input_channels = train_data.shape[1]  # Features dimension (19)\ninput_length = train_data.shape[2]    # Sequence length (500)\nnum_classes = len(class_mapping)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = Simple1DCNN(input_channels, input_length, num_classes).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:24:11.955024Z","iopub.execute_input":"2025-01-19T11:24:11.955343Z","execution_failed":"2025-01-19T11:32:28.839Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-75d7acf6bcdf>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Features dimension (19)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0minput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m    \u001b[0;31m# Sequence length (500)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimple1DCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: tuple index out of range"],"ename":"IndexError","evalue":"tuple index out of range","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-75d7acf6bcdf>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Features dimension (19)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0minput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m    \u001b[0;31m# Sequence length (500)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimple1DCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: tuple index out of range"],"ename":"IndexError","evalue":"tuple index out of range","output_type":"error"}],"execution_count":null},{"cell_type":"code","source":"class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\nclass_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T11:32:28.841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for batch in train_loader:\n    data, labels = batch\n    print(f\"Data shape: {data.shape}, Labels shape: {labels.shape}\")\n    break","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T11:32:28.842Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=30, patience=7):\n    best_val_loss = float(\"inf\")\n    epochs_no_improve = 0\n\n    for epoch in range(num_epochs):\n        model.train()\n        train_loss, train_correct = 0.0, 0\n\n        for data, labels in train_loader:\n            data, labels = data.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(data)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            train_correct += (outputs.argmax(1) == labels).sum().item()\n\n        train_acc = train_correct / len(train_loader.dataset)\n\n        model.eval()\n        val_loss, val_correct = 0.0, 0\n        with torch.no_grad():\n            for data, labels in val_loader:\n                data, labels = data.to(device), labels.to(device)\n                outputs = model(data)\n                loss = criterion(outputs, labels)\n\n                val_loss += loss.item()\n                val_correct += (outputs.argmax(1) == labels).sum().item()\n\n        val_acc = val_correct / len(val_loader.dataset)\n        scheduler.step(val_loss)\n\n        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), \"best_model_weights.pth\")\n            epochs_no_improve = 0\n        else:\n            epochs_no_improve += 1\n            if epochs_no_improve >= patience:\n                print(\"Early stopping triggered.\")\n                break\n\n    model.load_state_dict(torch.load(\"best_model_weights.pth\"))\n    return model","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T11:32:28.842Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trained_model = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=30)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T11:32:28.843Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Evaluating the model","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, roc_auc_score\nimport torch\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef evaluate_model(model, val_loader, class_names):\n    model.eval()\n    val_preds, val_labels = [], []\n    val_probs = []\n\n    with torch.no_grad():\n        for data, labels in val_loader:\n            data, labels = data.to(device), labels.to(device)\n            outputs = model(data)\n            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n            preds = outputs.argmax(1).cpu().numpy()\n\n            val_preds.extend(preds)\n            val_probs.extend(probs)\n            val_labels.extend(labels.cpu().numpy())\n\n    # Classification Report\n    print(\"Validation Classification Report:\")\n    print(classification_report(val_labels, val_preds, target_names=class_names))\n\n    # Balanced Accuracy Score\n    balanced_acc = balanced_accuracy_score(val_labels, val_preds)\n    print(f\"Balanced Accuracy Score: {balanced_acc:.4f}\")\n\n    # ROC AUC Score (One-vs-Rest)\n    try:\n        roc_auc = roc_auc_score(val_labels, val_probs, multi_class='ovr')\n        print(f\"ROC AUC Score (OvR): {roc_auc:.4f}\")\n    except ValueError:\n        print(\"ROC AUC Score could not be computed (ensure probabilities are provided and labels are multi-class).\")\n\n    # Confusion Matrix\n    cm = confusion_matrix(val_labels, val_preds)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()\n\nclass_names = [\"Normal\", \"Complex Partial Seizures\", \"Electrographic Seizures\", \"Video-detected Seizures\"]\nevaluate_model(trained_model, val_loader, class_names)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T11:32:28.844Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Making test predictions using the model","metadata":{}},{"cell_type":"code","source":"def generate_test_predictions(model, test_loader):\n    model.eval()\n    predictions = []\n    with torch.no_grad():\n        for data in test_loader:\n            data = data.to(device)\n            outputs = model(data)\n            preds = outputs.argmax(1).cpu().numpy()\n            predictions.extend(preds)\n    return predictions\n\ntest_predictions = generate_test_predictions(trained_model, test_loader)\n\ndef save_sorted_predictions(filenames, predictions, output_file=\"test_predictions_cnn1d_best1.csv\"):\n    results = pd.DataFrame({\"Filename\": filenames, \"Predicted Label\": predictions})\n    results[\"Numeric Order\"] = results[\"Filename\"].str.extract(r'(\\d+)').astype(int)\n    results = results.sort_values(by=\"Numeric Order\").drop(columns=[\"Numeric Order\"])\n    results.to_csv(output_file, index=False)\n    print(f\"Test predictions saved to {output_file}\")\n\nsave_sorted_predictions(test_filenames, test_predictions)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T11:32:28.844Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# PART 2","metadata":{}},{"cell_type":"markdown","source":"## 1. Installing LIME","metadata":{}},{"cell_type":"code","source":"!pip install lime","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T11:32:28.844Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Importing required libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom lime.lime_tabular import LimeTabularExplainer\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T11:32:28.845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trained_model.eval()\ndevice = torch.device(\"cpu\")\ntrained_model.to(device)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T11:32:28.845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_fn(inputs):\n    \"\"\"\n    A wrapper for the trained PyTorch model that outputs probabilities.\n    Reshapes the input to match the model's expected input shape.\n    \"\"\"\n    batch_size = inputs.shape[0]\n    inputs = inputs.reshape(batch_size, 19, 500)  # Reshape to (batch_size, num_channels, seq_length)\n    print(\"Input shape for model (before forward):\", inputs.shape)  # Debugging print\n\n    # Convert to torch tensor\n    inputs = torch.tensor(inputs, dtype=torch.float32).to(device)\n\n    # Model inference\n    with torch.no_grad():\n        logits = trained_model(inputs)  # Pass through the model\n        print(\"Logits shape:\", logits.shape)  # Debugging print\n        probabilities = torch.softmax(logits, dim=1).cpu().numpy()  # Convert to probabilities\n        print(\"Probabilities shape:\", probabilities.shape)  # Debugging print\n\n    return probabilities","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T11:32:28.845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"explainer = LimeTabularExplainer(\n    train_data.reshape(train_data.shape[0], -1),  # Flatten the EEG data (samples x features)\n    mode=\"classification\",\n    feature_names=[f\"Channel_{i}\" for i in range(train_data.shape[1])],\n    class_names=[\"Normal\", \"Complex Partial Seizures\", \"Electrographic Seizures\", \"Video-detected Seizures\"],\n    discretize_continuous=False\n)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T11:32:28.846Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def explain_sample(sample, model, explainer):\n    \"\"\"\n    Explains the model's prediction for a single sample using LIME.\n    \"\"\"\n    sample_flat = sample.reshape(-1)  # Flatten the sample\n    explanation = explainer.explain_instance(\n        sample_flat,\n        predict_fn,  # The prediction function defined earlier\n        num_features=train_data.shape[1],  # Number of EEG channels\n        top_labels=len(class_names)  # Number of classes to explain\n    )\n    return explanation","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T11:32:28.846Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Collect feature importance for each class\nimportance_by_class = defaultdict(list)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T11:32:28.846Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Generate explanations for a subset of the validation data\n# for i in range(100):  # Adjust this number based on computation limits\n#     sample = val_data[i]\n#     label = val_labels[i]\n\n#     explanation = explain_sample(sample, trained_model, explainer)\n#     class_idx = explanation.top_labels[0]  # Predicted class\n\n#     # Append the importance values for each channel\n#     for feature, importance in explanation.local_exp[class_idx]:\n#         channel_idx = feature // 500  # Map flattened feature index to channel index\n#         if channel_idx < len(feature_names):  # Ensure it's within valid range\n#             importance_by_class[class_idx].append((channel_idx, importance))\n\n# # Aggregate and find top 3 channels for each class\n# top_channels_by_class = {}\n# for class_idx, feature_importances in importance_by_class.items():\n#     # Aggregate importance values for each feature (within the 19-channel scope)\n#     aggregated = defaultdict(float)\n#     for feature, importance in feature_importances:\n#         aggregated[feature] += importance\n\n#     # Sort by importance and select the top 3\n#     sorted_channels = sorted(aggregated.items(), key=lambda x: x[1], reverse=True)[:3]\n#     top_channels_by_class[class_idx] = [feature_names[ch] for ch, _ in sorted_channels]\n\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T11:32:28.846Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Optional: Visualize top channel contributions\n# for class_idx, feature_importances in importance_by_class.items():\n#     aggregated = defaultdict(float)\n#     for feature, importance in feature_importances:\n#         aggregated[feature] += importance\n\n#     # Sort by importance\n#     sorted_importances = sorted(aggregated.items(), key=lambda x: x[1], reverse=True)\n#     channels, importances = zip(*sorted_importances)\n\n#     # Plot\n#     plt.figure(figsize=(10, 6))\n#     plt.barh([feature_names[ch] for ch in channels], importances, color=\"skyblue\")\n#     plt.xlabel(\"Importance\")\n#     plt.ylabel(\"EEG Channels\")\n#     plt.title(f\"Channel Importance for Class: {class_names[class_idx]}\")\n#     plt.gca().invert_yaxis()\n#     plt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T11:32:28.846Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ensure we sample from all classes in the validation set\ndef sample_from_each_class(data, labels, num_per_class=5):\n    \"\"\"\n    Ensure at least `num_per_class` samples are included for each class.\n    \"\"\"\n    sampled_data, sampled_labels = [], []\n    for class_idx in range(len(class_names)):\n        # Get indices of all samples for the current class\n        class_indices = np.where(labels == class_idx)[0]\n        \n        # Randomly sample `num_per_class` or fewer if not enough samples\n        selected_indices = np.random.choice(class_indices, size=min(num_per_class, len(class_indices)), replace=False)\n        \n        # Add the samples and labels\n        sampled_data.append(data[selected_indices])\n        sampled_labels.append(labels[selected_indices])\n    \n    # Concatenate samples from all classes\n    return np.concatenate(sampled_data, axis=0), np.concatenate(sampled_labels, axis=0)\n\n# Sample 1 instance per class (or fewer if not enough samples exist)\nsampled_data, sampled_labels = sample_from_each_class(val_data, val_labels, num_per_class=50)\n\n# Collect feature importance for each class\nimportance_by_class = defaultdict(list)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T11:32:28.847Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate feature names for LIME based on channels\nnum_channels = 19\nsequence_length = 500\nfeature_names = [f\"Channel_{i}\" for i in range(num_channels)]\n\n# Function to map flattened indices back to channels\ndef map_flat_index_to_channel(flat_index, sequence_length):\n    \"\"\"\n    Maps a flattened feature index to the corresponding EEG channel.\n    \"\"\"\n    return flat_index // sequence_length\n\n# Collect feature importance for each class\nimportance_by_class = defaultdict(list)\n\n# Generate explanations for the sampled data\nfor i in range(len(sampled_data)):\n    sample = sampled_data[i]\n    label = sampled_labels[i]\n\n    explanation = explain_sample(sample, trained_model, explainer)\n\n    # Iterate over all classes in the explanation\n    for class_idx in range(len(class_names)):\n        # Map feature indices to channels and append importance\n        for flat_index, importance in explanation.local_exp[class_idx]:\n            channel = map_flat_index_to_channel(flat_index, sequence_length)\n            importance_by_class[class_idx].append((channel, importance))\n\n# Aggregate and find top 3 channels for each class\ntop_channels_by_class = {}\nfor class_idx, feature_importances in c.items():\n    # Aggregate importance values for each channel\n    aggregated = defaultdict(float)\n    for channel, importance in feature_importances:\n        aggregated[channel] += importance\n\n    # Sort by importance and select the top 3\n    cc = sorted(aggregated.items(), key=lambda x: x[1], reverse=True)[:3]\n    top_channels_by_class[class_idx] = [f\"Channel_{ch}\" for ch, _ in sorted_channels]\n\n# Print results\nfor class_idx, top_channels in top_channels_by_class.items():\n    print(f\"Top 3 channels for class {class_names[class_idx]}: {top_channels}\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T11:32:28.847Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print results\nfor class_idx, top_channels in top_channels_by_class.items():\n    print(f\"Top 3 channels for class {class_names[class_idx]}: {top_channels}\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T11:32:28.847Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"aggregated_importance = defaultdict(list)\n\nfor class_idx, feature_importances in importance_by_class.items():\n    # Aggregate importance values for each channel\n    aggregated = defaultdict(float)\n    for channel, importance in feature_importances:\n        aggregated[channel] += importance\n\n    # Sort by importance\n    sorted_channels = sorted(aggregated.items(), key=lambda x: x[1], reverse=True)\n    aggregated_importance[class_idx] = sorted_channels\n    top_channels_by_class[class_idx] = [f\"Channel_{ch}\" for ch, _ in sorted_channels[:3]]\n\n# Plotting the importance for each class\nfor class_idx, sorted_channels in aggregated_importance.items():\n    plot_channel_importance(class_idx, sorted_channels, class_names)\n\n# Print top 3 channels\nfor class_idx, top_channels in top_channels_by_class.items():\n    print(f\"Top 3 channels for class {class_names[class_idx]}: {top_channels}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T11:32:28.847Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# PART 3","metadata":{}},{"cell_type":"code","source":"def mask_top_channels(data, top_channels_by_class, num_channels=19, sequence_length=500):\n    masked_data = data.copy()\n    for class_idx, top_channels in top_channels_by_class.items():\n        channel_indices = [int(channel.split('_')[1]) for channel in top_channels]\n        for channel_idx in channel_indices:\n            masked_data[:, channel_idx, :] = 0  # Mask the channel by setting to zero\n    return masked_data\n\nmasked_val_data = mask_top_channels(val_data, top_channels_by_class)\nmasked_test_data = mask_top_channels(test_data, top_channels_by_class)\n\nmasked_val_data = normalize_data(masked_val_data)\nmasked_test_data = normalize_data(masked_test_data)\n\nmasked_val_dataset = EEGDataset1D(masked_val_data, val_labels)\nmasked_test_dataset = EEGDataset1D(masked_test_data)\n\nmasked_val_loader = DataLoader(masked_val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\nmasked_test_loader = DataLoader(masked_test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n\ndef evaluate_model_with_masking(model, val_loader, class_names, top_channels_by_class=None):\n    model.eval()\n    val_preds, val_labels = [], []\n    val_probs = []\n\n    with torch.no_grad():\n        for data, labels in val_loader:\n            data, labels = data.to(device), labels.to(device)\n            outputs = model(data)\n            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n            preds = outputs.argmax(1).cpu().numpy()\n\n            val_preds.extend(preds)\n            val_probs.extend(probs)\n            val_labels.extend(labels.cpu().numpy())\n\n    print(\"Validation Classification Report (with masked top 3 channels):\")\n    print(classification_report(val_labels, val_preds, target_names=class_names))\n    \n    balanced_acc = balanced_accuracy_score(val_labels, val_preds)\n    print(f\"Balanced Accuracy Score: {balanced_acc:.4f}\")\n    \n    cm = confusion_matrix(val_labels, val_preds)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix (with masked top 3 channels)')\n    plt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-19T11:32:28.848Z"}},"outputs":[],"execution_count":null}]}